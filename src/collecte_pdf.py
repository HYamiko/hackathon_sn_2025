import os
import json
from pathlib import Path
import PyPDF2
import pdfplumber

# Configuration
PDF_DIR = "./pdfs_telecharges"  # Dossier contenant les PDFs
DATA_DIR = "../data"

# Cr√©er le dossier data s'il n'existe pas
os.makedirs(DATA_DIR, exist_ok=True)

# Structures de donn√©es (IDENTIQUES au script web)
corpus_data = []
source_list = []


def extract_text_pypdf2(pdf_path):
    """Extraction avec PyPDF2 (rapide mais parfois moins pr√©cis)."""
    try:
        text = ""
        with open(pdf_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            for page in reader.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        return text.strip()
    except Exception as e:
        print(f"   ‚ùå Erreur PyPDF2: {e}")
        return None


def extract_text_pdfplumber(pdf_path):
    """Extraction avec pdfplumber (plus lent mais plus pr√©cis)."""
    try:
        text = ""
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        return text.strip()
    except Exception as e:
        print(f"   ‚ùå Erreur pdfplumber: {e}")
        return None


def extract_pdf_title(pdf_path):
    """Extrait le titre du PDF depuis les m√©tadonn√©es."""
    try:
        with open(pdf_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            metadata = reader.metadata
            if metadata and metadata.get('/Title'):
                return metadata.get('/Title')
    except:
        pass

    # Fallback : utiliser le nom du fichier sans extension
    return os.path.splitext(os.path.basename(pdf_path))[0]


def clean_text(text):
    """Nettoie le texte extrait du PDF."""
    if not text:
        return ""

    # Supprimer les lignes vides multiples
    lines = [line.strip() for line in text.split('\n') if line.strip()]
    text = '\n'.join(lines)

    # Supprimer les caract√®res de contr√¥le ind√©sirables
    text = ''.join(char for char in text if char.isprintable() or char in '\n\t')

    # Supprimer les espaces multiples
    text = ' '.join(text.split())

    return text


def process_pdf(pdf_path):
    """
    Traite un fichier PDF et extrait son contenu.

    ‚ö†Ô∏è STRUCTURE DE RETOUR IDENTIQUE √Ä scrape_page()
    """
    pdf_name = os.path.basename(pdf_path)
    print(f"üìÑ Traitement de : {pdf_name}")

    # Essayer d'abord avec pdfplumber (plus fiable)
    content = extract_text_pdfplumber(pdf_path)

    # Si √©chec, essayer PyPDF2
    if not content or len(content) < 100:
        print(f"   ‚ö†Ô∏è  pdfplumber insuffisant, essai avec PyPDF2...")
        content = extract_text_pypdf2(pdf_path)

    # Nettoyer le texte
    if content:
        content = clean_text(content)

    # V√©rification de la qualit√© de l'extraction
    if not content or len(content) < 100:
        print(f"   ‚ö†Ô∏è  ATTENTION: Contenu insuffisant ({len(content) if content else 0} caract√®res)")
        print(f"   Le PDF est peut-√™tre scann√© (image) ou prot√©g√©.")
        return None

    print(f"   ‚úÖ Extrait : {len(content)} caract√®res")

    return content


# --- Ex√©cution de la collecte (IDENTIQUE au script web) ---
print("=" * 60)
print("üöÄ EXTRACTION DE TEXTE DEPUIS PDFs")
print("=" * 60 + "\n")

# Trouver tous les fichiers PDF
pdf_files = list(Path(PDF_DIR).glob('**/*.pdf'))

if not pdf_files:
    print(f"‚ùå Aucun fichier PDF trouv√© dans {PDF_DIR}")
else:
    print(f"üîç {len(pdf_files)} fichier(s) PDF trouv√©(s)\n")

    # Traiter chaque PDF (BOUCLE IDENTIQUE au script web)
    for i, pdf_path in enumerate(pdf_files, 1):
        print(f"[{i}/{len(pdf_files)}] Collecte de : {pdf_path}...")
        content = process_pdf(str(pdf_path))

        if content:
            # ‚ö†Ô∏è STRUCTURE STRICTEMENT IDENTIQUE √Ä scrape_page
            data_entry = {
                "id": len(corpus_data) + 1,
                "text": content,
                "source": str(pdf_path),
                "title": extract_pdf_title(str(pdf_path))
            }
            corpus_data.append(data_entry)
            source_list.append(str(pdf_path))

print(f"\nCollecte initiale termin√©e. {len(corpus_data)} documents bruts collect√©s.")

# --- Livrables Bruts (IDENTIQUES au script web) ---
# 1. data/corpus_brut.json
with open(os.path.join(DATA_DIR, "corpus_brut.json"), 'w', encoding='utf-8') as f:
    json.dump(corpus_data, f, ensure_ascii=False, indent=4)

# 2. data/sources_brut.txt
with open(os.path.join(DATA_DIR, "sources_brut.txt"), 'w', encoding='utf-8') as f:
    f.write("\n".join(source_list))

print(f"Livrables bruts sauvegard√©s dans le dossier '{DATA_DIR}/'.")


# ===== FONCTION BONUS POUR PDFs SCANN√âS (OCR) =====
def process_pdf_with_ocr(pdf_path):
    """
    Pour les PDFs scann√©s (images), utilise l'OCR.
    N√©cessite : pip install pytesseract pdf2image pillow
    Et Tesseract install√© sur le syst√®me.

    Retourne le texte dans le m√™me format que process_pdf()
    """
    try:
        from pdf2image import convert_from_path
        import pytesseract

        print(f"   üîç Tentative OCR...")

        # Convertir le PDF en images
        images = convert_from_path(pdf_path)

        text = ""
        for i, image in enumerate(images, 1):
            print(f"   OCR page {i}/{len(images)}...")
            page_text = pytesseract.image_to_string(image, lang='fra')  # 'fra' pour fran√ßais
            text += page_text + "\n"

        return clean_text(text)

    except ImportError:
        print("   ‚ùå OCR non disponible. Installez : pip install pytesseract pdf2image")
        return None
    except Exception as e:
        print(f"   ‚ùå Erreur OCR: {e}")
        return None